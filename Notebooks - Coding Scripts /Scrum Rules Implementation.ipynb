{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scrum Rules Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8c83ASf3Tu3a",
        "7MtFvQbGT_vM",
        "CLSoq5nRUF1X",
        "iOUYnRh3UPbp",
        "vOxLd6P5UTf9",
        "P9F2evpzUcqG",
        "onRIV_g-UfnY",
        "FPMWM2FpUjQ6",
        "wnKEvTLfUn2x",
        "WKMlr998UuJA",
        "dFlKtolBEbNA",
        "xRx4zCTNEjcE",
        "f6Wf600REmzT",
        "gI_Z3WXZEpin",
        "IxV5_aEbEsDe",
        "kYpoQdEDEuxW",
        "JwNdm7vcIdgC",
        "5KKz6f4TIgi5",
        "ufQufxqYIjc3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VJicEfpLB9c"
      },
      "source": [
        "## **Uploading and reading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fKGUgJHKetd"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG6K9BLWqViv"
      },
      "source": [
        "### **Run this cell of code only for the first time!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5A6S3Zezzec"
      },
      "source": [
        "!pip install colored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zCQdq1fqige"
      },
      "source": [
        "### **Read the Dataset and provide initial information about it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw85soiLLE6F"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import colored\n",
        "\n",
        "\n",
        "# COMMENT OUT AND IN THE DATASET OF THE PROJECT TO BE ANALYZED \n",
        "\n",
        "df = pd.read_csv(\"xd_cleaned.csv\")\n",
        "#df = pd.read_csv(\"apstud_cleaned.csv\")\n",
        "#df = pd.read_csv(\"tistud_cleaned.csv\")\n",
        "#df = pd.read_csv(\"mobile_cleaned.csv\")\n",
        "#df = pd.read_csv(\"mdl_cleaned.csv\")\n",
        "#df = pd.read_csv(\"dnn_cleaned.csv\")\n",
        "#df = pd.read_csv(\"mesos_cleaned.csv\")\n",
        "#df = pd.read_csv(\"mule_cleaned.csv\")\n",
        "#df = pd.read_csv(\"nexus_cleaned.csv\")\n",
        "#df = pd.read_csv(\"timob_cleaned.csv\")\n",
        "\n",
        "pd.set_option('display.max_rows', df.shape[0]+1)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 150)\n",
        "\n",
        "print(\"\\n******************************\\n\")\n",
        "print(\"Printing Dataset Initial Shape: \\n\")\n",
        "print(df.shape)\n",
        "print(\"\\n******************************\\n\")\n",
        "print(\"Printing Dataset Initial Descriptives: \\n\")\n",
        "print(df.describe())\n",
        "print(\"\\n******************************\\n\")\n",
        "print(\"Printing Dataset Information: \\n\")\n",
        "print(df.info())\n",
        "print(\"\\nCheck the data fields that contain missing values in the Open-Source Project \\n\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HXzXYrrD5Oa"
      },
      "source": [
        "### **Read the Changeset Dataset and provide initial information about it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s4fj-3RxU_z"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import colored\n",
        "\n",
        "\n",
        "# COMMENT OUT AND IN THE CHANGELOG DATASET OF THE PROJECT TO BE ANALYZED \n",
        "\n",
        "df_changelog = pd.read_csv(\"xd_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"apstud_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"tistud_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"mobile_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"mdl_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"dnn_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"mesos_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"mule_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"nexus_dataframe.csv\")\n",
        "#df_changelog = pd.read_csv(\"timob_dataframe.csv\")\n",
        "\n",
        "pd.set_option('display.max_rows', df_changelog.shape[0]+1)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 150)\n",
        "\n",
        "print(\"\\n******************************\\n\")\n",
        "print(\"Printing Dataset Initial Shape: \\n\")\n",
        "print(df_changelog.shape)\n",
        "print(\"\\n******************************\\n\")\n",
        "print(\"Printing Dataset Initial Descriptives: \\n\")\n",
        "print(df_changelog.describe())\n",
        "print(\"\\n******************************\\n\")\n",
        "print(\"Printing Dataset Information: \\n\")\n",
        "print(df_changelog.info())\n",
        "print(\"\\nCheck the data fields that contain missing values in the Open-Source Project \\n\")\n",
        "print(df_changelog.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAmAlbQxfGkZ"
      },
      "source": [
        "### **Insights on total Number of Issues, Sprints and Developers before running the rules:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq7AhJ4WUbMF"
      },
      "source": [
        "print(\"Number of issues: \\n\")\n",
        "print(df.key.nunique())\n",
        "print(df.key.unique())\n",
        "print('\\n\\n')\n",
        "print(len(df.key.unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGKAVpEMbElH"
      },
      "source": [
        "print(\"Number of sprints: \\n\")\n",
        "print(df.sprint.nunique())\n",
        "print(df.sprint.unique())\n",
        "print('\\n\\n')\n",
        "print(len(df.sprint.unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jeirKnObE6z"
      },
      "source": [
        "print(\"Number of developers: \\n\")\n",
        "print(df['assignee.name'].nunique())\n",
        "print(df['assignee.name'].unique())\n",
        "print('\\n\\n')\n",
        "print(len(df['assignee.name'].unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sLFUmiLfVM"
      },
      "source": [
        "# **Scrum Rules Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN0PEwEKiF7M"
      },
      "source": [
        "## **R1 - No more than five weeks should elapse for a single sprint**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irmMq4JnrgRa"
      },
      "source": [
        "### **Code for Mobile and MDL Projects!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbIIFLfllaTd"
      },
      "source": [
        "# REMOVE ISSUES WITH EMPTY SPRINT VALUE\n",
        "df = df[df['sprint'].notna()]\n",
        "\n",
        "df['sprint_start_date'] = df['sprint'].astype(str).str.extract('startDate=(.{,24})')\n",
        "df['sprint_end_date'] = df['sprint'].astype(str).str.extract('endDate=(.{,24})')\n",
        "df[\"sprint_id\"] = df[\"sprint\"].str.findall(r\"id\\=(\\d+),\")\n",
        "df['sprint_id'] = df['sprint_id'].str.join(',')\n",
        "\n",
        "# THE LINE OF CODE BELOW BELONGS ONLY TO MDL PROJECT \n",
        "#df = df.drop(df[df['sprint_start_date']== '<null>,endDate=<null>,co'].index)\n",
        "\n",
        "df['sprint_start_date'] = pd.to_datetime(df['sprint_start_date'])\n",
        "df['sprint_end_date'] = pd.to_datetime(df['sprint_end_date'])\n",
        "\n",
        "df.sprint_id.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmdGxvf8yhiF"
      },
      "source": [
        "len(df.sprint.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUL5NhaUmTiL"
      },
      "source": [
        "df[\"sprint_id\"] = df[\"sprint_id\"].str.replace(\",\",\"invalid\")\n",
        "df = df[~df.sprint_id.str.contains('invalid')]\n",
        "\n",
        "df.sprint_id = pd.to_numeric(df.sprint_id, errors='coerce')\n",
        "df = df.sort_values(by=['sprint'])\n",
        "df['difference_between_sprints_in_days'] = df['sprint_end_date'] - df['sprint_start_date']\n",
        "\n",
        "grouped_df = df.sort_values('sprint_start_date').groupby([\"sprint_id\"])\n",
        "#display(df[['sprint_id', 'sprint_start_date', 'sprint_end_date', 'difference_between_sprints_in_days']])\n",
        "first_values = grouped_df.first()\n",
        "display(first_values[['sprint_start_date', 'sprint_end_date', 'difference_between_sprints_in_days']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcz4s-bd1vjz"
      },
      "source": [
        "len(df.sprint_id.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmFuBFh4zspV"
      },
      "source": [
        "df.sprint_id.unique()\n",
        "\n",
        "sprints = [125, 106, 167, 289, 264, 195, 114, 136,  85, 170, 165,  79,  92, 160, 143, 202, 176,  75, 229,  95,  74, 152]\n",
        "sprints.sort()\n",
        "df = df[df['sprint_id'].isin(sprints)]\n",
        "\n",
        "df[['sprint_id', 'difference_between_sprints_in_days']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuX4oVCUrPyg"
      },
      "source": [
        "df['difference_between_sprints_in_days'].value_counts()\n",
        "\n",
        "#df.sprint.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH_iBg9XZGmM"
      },
      "source": [
        "df['difference_between_sprints_in_days'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWuOgbyHt0Nt"
      },
      "source": [
        "df['sprint_id'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-litVgJcu9xU"
      },
      "source": [
        "df['difference_between_sprints_in_days'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R-13bVN6dwS"
      },
      "source": [
        "### **Code for Mule Project!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGSG6wNqBKGX"
      },
      "source": [
        "df['sprint'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-PbsE__7mnR"
      },
      "source": [
        "# remove empty sprints\n",
        "df = df[df['sprint'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3AHDmT6hvj"
      },
      "source": [
        "df['sprint'] = df['sprint'].str.replace('startDate=', '')\n",
        "df['sprint'] = df['sprint'].astype(object).replace('<null>', np.nan)\n",
        "\n",
        "df['sprint']= pd.to_datetime(df['sprint'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDGFJSdt6mad"
      },
      "source": [
        "len(df['sprint'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F015Am1uBNy0"
      },
      "source": [
        "df['sprint'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU0Ri2FK6rMe"
      },
      "source": [
        "df_sorted = df.sort_values(by=['sprint'])\n",
        "df_sorted['difference'] = (df_sorted['sprint'] - df_sorted['sprint'].shift(1)).dt.days\n",
        "print(df_sorted.difference.describe())\n",
        "df_sorted = df_sorted.groupby('sprint')\n",
        "first_values = df_sorted.first()\n",
        "display(first_values[['difference']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8LFIMfWDYSU"
      },
      "source": [
        "df_sorted['difference'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dhCexvRCDZa"
      },
      "source": [
        "# df['count_difference'] = (df['sprint'] - df['sprint'].shift(1)).dt.days \n",
        "\n",
        "# df[df['count_difference'] > 28.0 ].count() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QltSVc17YfQ"
      },
      "source": [
        "df_sorted.difference.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6tOsuemFAgH"
      },
      "source": [
        "## **R4 - The duration of all sprints should follow similar pace**\n",
        "\n",
        "## **#This Rule is checked and reported through R1!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLSFSvI0FF1F"
      },
      "source": [
        "## **R5 - The next Sprint execution should begin only after the previous Sprint's resolution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7gnKIqc0EJH"
      },
      "source": [
        "df = df[df['sprint'].notna()]\n",
        "\n",
        "df['sprint_start_date'] = df['sprint'].astype(str).str.extract('startDate=(.{,24})')\n",
        "df['sprint_end_date'] = df['sprint'].astype(str).str.extract('endDate=(.{,24})')\n",
        "\n",
        "df[\"sprint_id\"] = df[\"sprint\"].str.findall(r\"id\\=(\\d+),\")\n",
        "df['sprint_id'] = df['sprint_id'].str.join(',')\n",
        "\n",
        "df = df.drop(df[df['sprint_start_date']== '<null>,endDate=<null>,co'].index)\n",
        "\n",
        "df['sprint_start_date'] = pd.to_datetime(df['sprint_start_date'])\n",
        "df['sprint_end_date'] = pd.to_datetime(df['sprint_end_date'])\n",
        "\n",
        "df['day_of_creation'] = df.sprint_start_date.dt.dayofyear\n",
        "df['day_of_completion'] = df.sprint_end_date.dt.dayofyear \n",
        "\n",
        "#df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WneVixPYeTZf"
      },
      "source": [
        "final_df = df.sort_values(by=['sprint_start_date'], ascending=True)\n",
        "\n",
        "final_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUhWOMAO0_kB"
      },
      "source": [
        "# Run only for MDL\n",
        "\n",
        "df[\"sprint_id\"] = df[\"sprint\"].str.findall(r\"id\\=(\\d+),\")\n",
        "df['sprint_id'] = df['sprint_id'].str.join(',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YXlRl91fvgJ"
      },
      "source": [
        "df[\"sprint_id\"] = df[\"sprint_id\"].str.replace(\",\",\"invalid\")\n",
        "df = df[~df.sprint_id.str.contains('invalid')]\n",
        "\n",
        "df.sprint_id = pd.to_numeric(df.sprint_id, errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKs4CFl30Ge1"
      },
      "source": [
        "final_df = df.sort_values(by=['sprint_start_date'], ascending=True)\n",
        "\n",
        "final_df['difference'] = (final_df['sprint_start_date'] - final_df['sprint_end_date'].shift(1)).dt.days\n",
        "final_df.head(20)\n",
        "\n",
        "#df = df.sort_values(by=['sprint_id'])\n",
        "\n",
        "grouped_df = final_df.groupby(\"sprint_id\")\n",
        "first_values = grouped_df.first()\n",
        "display(first_values[[ 'sprint_start_date', 'sprint_end_date', 'day_of_creation', 'day_of_completion',  'difference']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37uePcR34mnw"
      },
      "source": [
        "first_values.difference.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8qBvcw5451N"
      },
      "source": [
        "first_values.difference.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXSRk5dlFaoF"
      },
      "source": [
        "## **R6 - There should be a project clarity identifier attached to each issue**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8NsDuqXGRWq"
      },
      "source": [
        "# THIS RULE CHECKS IF ALL ISSUES IN THE PROJECT, WITHIN THEIR CORRESPONDING SPRINTS\n",
        "# HAVE a PROJECT Clarity Identifier assosciated with them, which indicates that the issue belongs to a valid project.\n",
        "\n",
        "print(f'Total number of issues present in this Open-Source Project is: {df.key.nunique()}.')\n",
        "print(f'Total number of missing issues present in this Open-Source Project is: {df.key.isnull().sum()}.\\n')\n",
        "print(f'Total number of sprints present in this Open-Source Project is: {df.sprint.nunique()}.')\n",
        "print(f'Total number of missing sprint IDs present in this Open-Source Project is: {df.sprint.isnull().sum()}.\\n')\n",
        "\n",
        "grouped_df = df.groupby(\"sprint\")\n",
        "\n",
        "print('\\n\\n*      FIRST SPRINT       *\\n\\n')\n",
        "for key, item in grouped_df:\n",
        "  if item.iloc[0]['project'] != item['project'].iloc[0]:\n",
        "    print(\"False\")\n",
        "  else: \n",
        "    print(\"True\")\n",
        "    # print(grouped_df[['key', 'project']].get_group(key).to_markdown())\n",
        "    #print('\\n\\n*      NEXT SPRINT       *\\n\\n')\n",
        "    \n",
        "r7_df = df[(df['project'].isnull()) & pd.notnull(df[\"key\"])]\n",
        "\n",
        "if (len(r7_df[['key', 'sprint']]) == 0) :\n",
        "  print(colored.fg(\"green\") + \"\\nRule 7 passed for this Open-Source Project!\\n\")\n",
        "  print(f'Total number of missing project clarity IDs present in this Open-Source Project is: {df.project.isnull().sum()}.\\n')\n",
        "else :\n",
        "  print(colored.fg(\"red\") + \"\\nRule 7 failed for this Open-Source Project!\\n\")\n",
        "\n",
        "r7_df[['sprint', 'key']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX3z3ypXFfiV"
      },
      "source": [
        "## **R7 - No considerable amount of time should elapse between the finish of a sprint and the beginning of the new sprint**\n",
        "\n",
        "## **This rule is checked through R1!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoXfwlD5FnYV"
      },
      "source": [
        "## **R8 - There should not be a considerable amount of time for a developer to volunteer and start a new issue after she/he has completed the previous one**\n",
        "\n",
        "## **This rule should be checked AFTER #R28 has been checked!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXnpnY-eGSfo"
      },
      "source": [
        "# rename the column: assignee.name, to have the new name: developers\n",
        "#df.rename(columns={'assignee.name': 'developers'}, inplace=True)\n",
        "\n",
        "#df.head()\n",
        "\n",
        "MAX_DAY = 2.0\n",
        "counter = 0\n",
        "\n",
        "# For each project, take the list of active developers, and then remove all other developers that are not active part of the team!\n",
        "\n",
        "# print(\"for XD\")\n",
        "#ACTIVE_DEVS = ['grussell', 'dturanski', 'iperumal', 'hillert', 'eric.bottard', 'thomas.risberg', 'grenfro']\n",
        "\n",
        "# print(\"for APSTUD\")\n",
        "#ACTIVE_DEVS = ['cwilliams', 'pinnamuri', 'mxia', 'sgibly']\n",
        "\n",
        "# print(\"for TISTUD\")\n",
        "#ACTIVE_DEVS = ['pinnamuri', 'sgibly', 'mxia', 'cwilliams', 'kkolipaka']\n",
        "\n",
        "# print(\"for MOBILE\")\n",
        "#ACTIVE_DEVS = ['dpalou', 'jleyva', 'pferre22']\n",
        "\n",
        "# print(\"for MDL\")\n",
        "#ACTIVE_DEVS = ['timhunt', 'mudrd8mz', 'dobedobedoh', 'danmarsden', 'jleyva', 'stronk7', 'marina', 'dmonllao', 'fred', 'quen', 'markn', 'damyon', 'dougiamas', 'moodle.com', 'ankit_frenz', 'poltawski', 'rajeshtaneja', 'andyjdavis', 'skodak', 'samhemelryk', 'jerome', 'dongsheng', 'lazyfish']\n",
        "\n",
        "# print(\"for DNN\")\n",
        "#ACTIVE_DEVS = ['bing.wu', 'robert.cui', 'KenGrierson', 'Amritpal.Manak', 'mohit', 'behzad.basir']\n",
        "\n",
        "# print(\"for MESOS\")\n",
        "#ACTIVE_DEVS = ['js84', 'jieyu', 'kaysoky', 'jojy', 'anandmazumdar', 'jvanremoortere', 'greggomann', 'gilbert', 'vinodkone', 'alexr', 'mcypark', 'karya', 'bmahler']\n",
        "\n",
        "# print(\"for MULE\")\n",
        "#ACTIVE_DEVS = ['mariano.gonzalez', 'rodrigo.merino', 'afelisatti', 'pablo.lagreca.ce', 'pablo.kraan', 'andres.gregoire', 'marcosnc']\n",
        "\n",
        "# print(\"for NEXUS\")\n",
        "#ACTIVE_DEVS = ['jtom', 'cstamas', 'alin', 'plynch']\n",
        "\n",
        "# print(\"for TIMOB\")\n",
        "#ACTIVE_DEVS = ['kota', 'cwilliams', 'msamah', 'gmathews', 'hansknoechel', 'cng', 'penrique', 'hpham', 'cbarber', 'vduggal']\n",
        "\n",
        "df = df[df['developers'].isin(ACTIVE_DEVS)]\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "# Remove issues with no end date, and issues belonging to no sprints!\n",
        "df = df[df['resolutiondate'].notna()]\n",
        "df = df[df['sprint'].notna()]\n",
        "df = df[df['developers'].notna()]\n",
        "#df.shape\n",
        "\n",
        "# Extract days from created and resolutiondate\n",
        "df['created'] = pd.to_datetime(df.created, utc=True)\n",
        "df['resolutiondate'] = pd.to_datetime(df.resolutiondate, utc=True)\n",
        "df['day_of_creation'] = df.created.dt.dayofyear\n",
        "df['day_of_completion'] = df.resolutiondate.dt.dayofyear \n",
        "df['issue_completion_time'] =  df.resolutiondate - df.created\n",
        "\n",
        "df.head()\n",
        "\n",
        "grouped_df = df.sort_values(['sprint', 'created', 'key']).groupby([\"sprint\", \"developers\"])\n",
        "\n",
        "# grouped_df.sort_values(by=['sprint', 'created', 'priority.name'])\n",
        "print('\\n\\n*      FIRST SPRINT       *\\n\\n')\n",
        "for key, item in grouped_df:\n",
        "    print(f\"Key is: {key}\")\n",
        "    #item.sort_index()\n",
        "    item['diff'] = (item['created'] - item['resolutiondate'].shift(1)).dt.days \n",
        "    print(f\"{item[['key', 'developers', 'issue_completion_time', 'diff']].to_markdown()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ietzInY0am_d"
      },
      "source": [
        "## **R24 - The backlog does not contain meaningless or empty issues. I consider meaningless issues the issues that belong to no project and have no issue body, description, start and end time and other details that are relevant to developers and other roles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVjpgnc8ayM5"
      },
      "source": [
        "# A meaningless issue corresponds to an issue which does not have any description and/or summary. \n",
        "# Description field is more important in this rule.  \n",
        "# Moreover, we can check in this rule whether all issues have any missing status names, priority labels and story points."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo2leqJbc22l"
      },
      "source": [
        "# rename the column: status.name, to have the new name: status\n",
        "df.rename(columns={'status.name': 'status'}, inplace=True)\n",
        "#df.head()\n",
        "\n",
        "for column in df:\n",
        "    if df[column].isnull().any():\n",
        "       print('{0} has {1} null values'.format(column, df[column].isnull().sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdFfU35jVsEV"
      },
      "source": [
        "cols = ['description', 'summary', 'status', 'project', 'storypoints', 'priority.name']\n",
        "#df.sprint = pd.to_numeric(df.sprint, errors='coerce')\n",
        "df = df.sort_values(by=\"sprint\", ascending=False)\n",
        "print(\"\\n      CHECKING IF THERE ARE MISSING INFORMATION IN THE DESCRITPIVE FIELDS OF THE ISSUES \\n\\n\")\n",
        "df.set_index('sprint')[cols].isna().sum(level=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOxMC0RUcaNp"
      },
      "source": [
        "meaningless_issues_per_sprint = df.groupby('sprint').description.nunique()\n",
        "pd.set_option('display.max_rows', df.shape[0]+1)\n",
        "meaningless_issues_per_sprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lueIGMy74UIt"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muI0IUyAkHoe"
      },
      "source": [
        "df.sprint.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoZ6-h5845Aw"
      },
      "source": [
        "no_end_date_df = df[['key', 'sprint', 'priority.name']][df['priority.name'].isna()]\n",
        "no_end_date_df.sort_values(by=\"sprint\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_R5mwUwkwCa"
      },
      "source": [
        "no_end_date_df = df[['key', 'sprint', 'priority.name', 'project', 'description']][df['storypoints'].isna()]\n",
        "no_end_date_df.sort_values(by=\"sprint\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p81biEVm9kLV"
      },
      "source": [
        "no_end_date_df = df[['key', 'sprint']][df['resolutiondate'].isna()]\n",
        "no_end_date_df.sort_values(by=\"sprint\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTcjzxaFOu7N"
      },
      "source": [
        "## **R27 - \"No more than 8 active developers should be involved in development tasks\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTMZwI-YRFFd"
      },
      "source": [
        "# rename the column: assignee.name, to have the new name: developers\n",
        "df.rename(columns={'assignee.name': 'developers'}, inplace=True)\n",
        "\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oakw6ZEkXfpk"
      },
      "source": [
        "print(df.key.count())\n",
        "print('\\n\\n')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(f\"\\n\\nOut of {df.key.count()} issues, {df.key.count()-df.developers.isnull().sum()} of them have developers assigned to them.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvQNGjm8PxA0"
      },
      "source": [
        "# Checking how many unique sprints are there (excluding if there is nan values):\n",
        "\n",
        "print(\"\\nCheck the total number of sprints in the Open-Source Project \\n\")\n",
        "\n",
        "print(df.sprint.nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atEd7cwbXG73"
      },
      "source": [
        "# Checking the most active developers\n",
        "print(df.developers.describe())\n",
        "print('\\n\\n')\n",
        "print(df.developers.value_counts())\n",
        "print(df.developers.value_counts().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjCaviGkQptH"
      },
      "source": [
        "value_counts = df['developers'].value_counts()\n",
        "\n",
        "#to_remove = value_counts[value_counts <= df.developers.value_counts().mean()].index\n",
        "\n",
        "#print('for xd')  \n",
        "#to_remove = value_counts[value_counts <= 98].index\n",
        "\n",
        "#print('for apstud')\n",
        "#to_remove = value_counts[value_counts <= 59].index\n",
        "\n",
        "#print('tistud')\n",
        "#to_remove = value_counts[value_counts <= 100].index\n",
        "\n",
        "#print('mobile')\n",
        "#to_remove = value_counts[value_counts <= 100].index\n",
        "\n",
        "#mdl\n",
        "#to_remove = value_counts[value_counts <= 386].index\n",
        "\n",
        "#dnn\n",
        "#to_remove = value_counts[value_counts <= 62].index\n",
        "\n",
        "#mesos\n",
        "#to_remove = value_counts[value_counts <= 31].index\n",
        "\n",
        "#mule\n",
        "#to_remove = value_counts[value_counts <= 73].index\n",
        "\n",
        "#nexus\n",
        "#to_remove = value_counts[value_counts <= 56].index\n",
        "\n",
        "#timob  \n",
        "#to_remove = value_counts[value_counts <= 73].index\n",
        "\n",
        "# Keep rows where the developers column is not in to_remove\n",
        "df = df[~df.developers.isin(to_remove)]\n",
        "\n",
        "devs_per_sprint = df.groupby('sprint').developers.nunique()\n",
        "\n",
        "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "pd.set_option('display.max_rows', df.shape[0]+1)\n",
        "\n",
        "devs_per_sprint.sort_values(ascending=False)\n",
        "#print(devs_per_sprint.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQFR52hkwT2U"
      },
      "source": [
        "# Checking how many unique issues are there after removing non-active developers:\n",
        "\n",
        "print(\"\\nCheck the total number of sprints in the Open-Source Project \\n\")\n",
        "\n",
        "print(df.key.nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buEywpM0v_pk"
      },
      "source": [
        "# Checking how many unique sprints are there after removing non-active developers:\n",
        "\n",
        "print(\"\\nCheck the total number of sprints in the Open-Source Project \\n\")\n",
        "\n",
        "print(df.sprint.nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzE0q_R1uijV"
      },
      "source": [
        "print(\"Number of active developers: \\n\")\n",
        "print(df['developers'].nunique())\n",
        "print(df['developers'].unique())\n",
        "print('\\n\\n')\n",
        "print(len(df['developers'].unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZc7d6MwdCFx"
      },
      "source": [
        "## **R28 - The status of issues should always follow the agreed workflow, depending on the project and development team**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c83ASf3Tu3a"
      },
      "source": [
        "### **1. XD Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suQhCJOZR4mV"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqL8haJpRtIe"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1uBSScwUqgs"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovrTfdyST4iM"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-LNgILhZud"
      },
      "source": [
        "statuses_to_keep_for_xd = [3, 10000, 10001, 10006]\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_xd)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_xd)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSyZDE9fhcTn"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])\n",
        "df_changelog['to'] = df_changelog['to'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsAA2whFhehQ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QCDnx7gWR6N"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG3Vmj4nWtMo"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF_0v3aDVi-c"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNYlF5BH4Cxv"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofuuBs8KhzSO"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW1Yhf19ioXd"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6wSmMpQjN4T"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VFwqL3KOWeE"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiBiWHcqIEjn"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcZVxEALIOpm"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZwIM8HIRv2"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MtFvQbGT_vM"
      },
      "source": [
        "### **2. APSTUD Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYdtpaqGT_vN"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3xv3oIMT_vN"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTYPYkcmT_vN"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1puiScKT_vN"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlvjUMMaT_vN"
      },
      "source": [
        "statuses_to_keep_for_apstud = [1, 10003, 5, 6, 4]\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_apstud)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_apstud)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvg0O2kAT_vN"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 10003, 5, 6, 4],[1, 5, 20, 50, 100])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 10003, 5, 6, 4],[1, 5, 20, 50, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B25vG7zRT_vN"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbYm4SuoT_vN"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DqkN_axT_vN"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9XcoWIkT_vO"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VHNwc_BT_vO"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOWTLErST_vO"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu6n4CKdT_vO"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l72a86BAT_vO"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HqUhORkT_vO"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kRvv1hlT_vO"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceT4EXhjT_vO"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXELAX-8T_vO"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLSoq5nRUF1X"
      },
      "source": [
        "### **3. TISTUD Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDoXcThvUF1Y"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYN-z0qhUF1Y"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDNYSzI1UF1Y"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdk9luwNUF1Y"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kevjmwbEUF1Y"
      },
      "source": [
        "statuses_to_keep_for_tistud = [1, 3, 10003, 5, 6, 4]\n",
        "\n",
        "# Reopened 4\n",
        "# Closed 6\n",
        "# Resolved 5\n",
        "# Open 1\n",
        "# In Review 10003\n",
        "# In Progress 3\n",
        "\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_tistud)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_tistud)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d90wGtKwUF1Y"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlNSa9ZoUF1Y"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psFicyTYUF1Y"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQWAmTLdUF1Y"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPTNyD3JUF1Y"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3EH-l0hUF1Y"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM5CdmQLUF1Z"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT2lS6fpUF1Z"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JHd2hY_UF1Z"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXQYZgK_UF1Z"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe40gmtuUF1Z"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqw3oM67UF1Z"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hORXIntvUF1Z"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_2MCee9wn-Z"
      },
      "source": [
        "df['status.id'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGGJXpElxKn3"
      },
      "source": [
        "df['status.name'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOUYnRh3UPbp"
      },
      "source": [
        "### **4. MOBILE Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZyfXVnpUPbp"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFjEI-RfUPbp"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2VGZYBzUPbp"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuk8KgSpUPbp"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb83txOZUPbq"
      },
      "source": [
        "statuses_to_keep_for_mobile = [1, 3, 10005, 10010, 10012, 5, 6, 4]\n",
        "\n",
        "# Open 1\n",
        "# Dev in progress 3\n",
        "# closed 6\n",
        "# Resolved                        5 \n",
        "\n",
        "# waiting for integration review 10010\n",
        "# Waiting for testing\t10005\n",
        "# Waiting for peer review         10012    \n",
        "\n",
        "# Reopened                        4 \n",
        "\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_mobile)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_mobile)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E5kEYHEUPbq"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 3, 10005, 10010, 10012, 5, 6, 4],[1, 5, 20, 50, 100, 200, 400, 800])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 3, 10005, 10010, 10012, 5, 6, 4],[1, 5, 20, 50, 100, 200, 400, 800])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "578sI-_-UPbq"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vmsFtwYUPbq"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZHZQ5IYUPbq"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMtnJ1X6UPbq"
      },
      "source": [
        "df_changelog['to'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN3YOtlBUPbq"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLQp4p_4UPbq"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrThTTLRUPbq"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZTUPojPUPbq"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfUj7Y-eUPbq"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXkvt3ljUPbq"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3WI3BbtUPbq"
      },
      "source": [
        "df['status.id'].unique()\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE-cOJA1UPbq"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jnhtE7DyStG"
      },
      "source": [
        "df[['status.name', 'status.id']].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOxLd6P5UTf9"
      },
      "source": [
        "### **5. MDL Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59QZe2r_UTf9"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjjsd67NUTf-"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLnK7MgBUTf-"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGkWfPfdUTf-"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3wZMXuqUTf-"
      },
      "source": [
        "statuses_to_keep_for_mdl = [1, 3, 6, 4, 10012, 10013, 10010, 10004, 10005, 10006 ]\n",
        "\n",
        "# Closed                          6            52988\n",
        "# Open                            1             9270\n",
        "# Reopened                        4              492\n",
        "# Development in progress         3              361\n",
        "# Waiting for peer review         10012           84\n",
        "# Waiting for integration review  10010           32\n",
        "# Peer review in progress         10013           30\n",
        "# Tested                          10006            9\n",
        "# Integration review in progress  10004            6\n",
        "# Waiting for testing             10005            2\n",
        "\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_mdl)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_mdl)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5xG9-xIUTf-"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])\n",
        "df_changelog['to'] = df_changelog['to'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgiI_sRTUTf-"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h-gmfsrUTf-"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6LUttUkUTf-"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpyI9T62UTf-"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfUq63tGUTf-"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFM4YcPmUTf-"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga_Dao22UTf-"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lI93kEPUTf-"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIcI2jXgUTf-"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORWHkmdFUTf-"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kAfu3LjUTf-"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4_YBJFIUTf_"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH9GdtYS5K2V"
      },
      "source": [
        "df[['status.name', 'status.id']].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9F2evpzUcqG"
      },
      "source": [
        "### **6. DNN Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeJmvkmrUcqH"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8CZmqIsUcqH"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vITyqPfHUcqH"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLdmTk7bUcqH"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbMDtvtgUcqH"
      },
      "source": [
        "statuses_to_keep_for_dnn = [1, 10008, 10133, 5, 6, 4]\n",
        "\n",
        "# Closed                  6 \n",
        "# Open                    1\n",
        "# Reopened                4 \n",
        "# Pull Request Submitted  10133\n",
        "# Planned Development     10008\n",
        "# Resolved                5\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_dnn)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_dnn)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFq_F0WvUcqH"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 10008, 10133, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 10008, 10133, 5, 6, 4],[1, 5, 20, 50, 100, 200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxYuRJQrUcqH"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxLJmRrkUcqH"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B446G1pYUcqH"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPJ3_rXsUcqH"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9YbdxMvUcqH"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXPmbCq6UcqH"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFhfnVBCUcqH"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCPn0yDAUcqI"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4daH2zKUcqI"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHdRSZ6FUcqI"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyE2ShdaUcqI"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kltEyyfOUcqI"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6wI2uAuzlam"
      },
      "source": [
        "df[['status.name', 'status.id']].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onRIV_g-UfnY"
      },
      "source": [
        "### **7. MESOS Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG91OvJgUfnY"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEvh3AtZUfnY"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYG2lkEAUfnY"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExCJIcvxUfnY"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTOWGx8IUfnZ"
      },
      "source": [
        "statuses_to_keep_for_mesos = [1, 3, 10006, 10020, 5]\n",
        "\n",
        "# Resolved     5            1088\n",
        "# Accepted     10020         136\n",
        "# Reviewable   10006          65\n",
        "# Open         1              56\n",
        "# In Progress  3 \n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_mesos)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_mesos)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP7PhacgUfna"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 3, 10006, 10020, 5],[1, 5, 20, 50, 100])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 3, 10006, 10020, 5],[1, 5, 20, 50, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z0rtsaUUfna"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX3Oh71sUfna"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRzv5vlZUfna"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdKhWd1WUfnb"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbIyT59UUfnc"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YlBfATJUfnd"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0-JI-LuUfnd"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZDNJCJuUfnd"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuMuMfDuUfnd"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADfPFV5dUfnd"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08pRVCtcUfnd"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKnQFN09Ufnd"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n94DWwl30hyv"
      },
      "source": [
        "df[['status.name', 'status.id']].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPMWM2FpUjQ6"
      },
      "source": [
        "### **8. MULE Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG-ZsceTUjQ7"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FENChpKoUjQ7"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yAod1qsUjQ7"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHmTXpA2UjQ7"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GOnP0QgUjQ7"
      },
      "source": [
        "statuses_to_keep_for_mule = [1, 3, 5, 6, 4]\n",
        "\n",
        "# Closed       6            1196\n",
        "# To Do        1              69\n",
        "# In Progress  3               7\n",
        "# Resolved     5               4\n",
        "# Reopened     4\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_mule)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_mule)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb0kRBe7UjQ7"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 3, 5, 6, 4],[1, 5, 20, 50, 100])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 3, 5, 6, 4],[1, 5, 20, 50, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAkQmmrnUjQ7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzS3dNCoUjQ7"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fs8wtZnUjQ7"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWfk9zvTUjQ8"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL3hUMYXUjQ8"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75pQTRqpUjQ8"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_3HH319UjQ8"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hEO4r5iUjQ8"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWRSzsFtUjQ8"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ltrDI6sUjQ8"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpqIRRyAUjQ8"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMkmSG0vUjQ8"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFx9yAzJ3AjF"
      },
      "source": [
        "df[['status.name', 'status.id']].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnKEvTLfUn2x"
      },
      "source": [
        "### **9. NEXUS Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5etpVo2-Un2x"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pMwB_HjUn2x"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L61tgIDUn2x"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpqmmSCsUn2x"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59ZcKletUn2y"
      },
      "source": [
        "statuses_to_keep_for_nexus = [1, 10016, 10734, 10017, 6]\n",
        "\n",
        "# Closed       6            967\n",
        "# Open         1             40\n",
        "# Done         10017         28\n",
        "# Refine       10734          1\n",
        "# Raw          10016  \n",
        "\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_nexus)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_nexus)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLzb1TWlUn2y"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 10016, 10734, 10017, 6],[1, 5, 20, 50, 100])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 10016, 10734, 10017, 6],[1, 5, 20, 50, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU7KSEatUn2y"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR8m09N9Un2y"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct93WrStUn2y"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQXMzQgjUn2y"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrwsUmOOUn2y"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23_FkvjoUn2y"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLUvU-z9Un2z"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qDdiog5Un2z"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVKl7EOPUn2z"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi7tXbjeUn2z"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5n1cxK8Un2z"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsJRaBpgUn2z"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rlvb3u84jcC"
      },
      "source": [
        "df[['status.name', 'status.id']].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKMlr998UuJA"
      },
      "source": [
        "### **10. TIMOB Project:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvFmKoZDUuJA"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqARWtxXUuJA"
      },
      "source": [
        "df_changelog.dropna(subset = [\"from\"], inplace=True)\n",
        "df_changelog.dropna(subset = [\"to\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyllDpreUuJA"
      },
      "source": [
        "df_changelog = df_changelog[~df_changelog['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "df_changelog = df_changelog[~df_changelog['to'].str.contains(\"[a-zA-Z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_CcKvbpUuJA"
      },
      "source": [
        "df_changelog['from'] = pd.to_numeric(df_changelog['from'], errors='coerce')\n",
        "df_changelog['to'] = pd.to_numeric(df_changelog['to'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7pdFvBRUuJA"
      },
      "source": [
        "statuses_to_keep_for_timob = [1, 3, 10003, 5, 6, 4]\n",
        "\n",
        "# Closed       6            916\n",
        "# Resolved     5            763\n",
        "# Open         1            121\n",
        "# Reopened     4             25\n",
        "# In Progress  3             15\n",
        "# In  Review   10003         13\n",
        "\n",
        "df_changelog = df_changelog[df_changelog['to'].isin(statuses_to_keep_for_timob)]\n",
        "df_changelog = df_changelog[df_changelog['from'].isin(statuses_to_keep_for_timob)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOeEgh5yUuJB"
      },
      "source": [
        "df_changelog['from'] = df_changelog['from'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "df_changelog['to'] = df_changelog['to'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1NODka3UuJB"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_changelog['from'] = df_changelog['from'].apply(np.int64)\n",
        "df_changelog['to'] = df_changelog['to'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBsbpmWkUuJB"
      },
      "source": [
        "df_changelog.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpU5meHiUuJB"
      },
      "source": [
        "df_changelog.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBQLRfcGUuJB"
      },
      "source": [
        "df_changelog['from'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuK6ApJSUuJB"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "df_changelog['status_deviations_field'] = df_changelog['to'] - df_changelog['from']\n",
        "\n",
        "grouped_df = df_changelog.groupby(\"key\")\n",
        "grouped_df.to.value_counts()\n",
        "#grouped_df.to_csv('XD_WORKFLOW.csv')\n",
        "\n",
        "#for key, item in grouped_df:\n",
        "    #print(grouped_df[['key', 'from', 'to']].get_group(key).to_markdown())\n",
        "    #print(\"key is\", key)\n",
        "    #print(\"item is\", item[['from', 'to']])\n",
        "   \n",
        "   # converet float values to int: 1, 2, 3, 4 and then calculate difference from next status - previous one, e.g. 4 - 2 = 2.\n",
        "   # Then in a new column present the final difference: status_deviations_field\n",
        "   # Then, check value_counts for the new column\n",
        "   # Then check only for negative values somehow and see in more detail what went wrong.\n",
        "   # Done = 10\n",
        "   \n",
        "   \n",
        "   \n",
        "    # if (pd.isnull(grouped_df['key'])):\n",
        "    #   print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "    #   #exit()\n",
        "    # else:\n",
        "    #   print('\\n\\n*        TRUE        *\\n\\n')\n",
        "    #   print('\\n\\n*        NEXT SPRINT        *\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6xG8ymYUuJB"
      },
      "source": [
        "df_changelog.status_deviations_field.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6_pthnKUuJB"
      },
      "source": [
        "values = [-30, -45, -49]\n",
        "\n",
        "df_changelog.loc[df_changelog['status_deviations_field'].isin(values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bEZKUUkUuJB"
      },
      "source": [
        "df_changelog.loc[df_changelog['key'] == 'XD-3684']\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwkyo52JUuJC"
      },
      "source": [
        "df_changelog = df_changelog.sort_values(['key', 'created'], ascending=[True, True])\n",
        "\n",
        "df_changelog = df_changelog.set_index('key')\n",
        "\n",
        "print (df_changelog.index[df_changelog['from']].tolist())\n",
        "print (df_changelog.index[df_changelog['to']].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGeq8AmrUuJD"
      },
      "source": [
        "df['status.name'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yGgx7VgUuJD"
      },
      "source": [
        "df['status.id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-z6fE2ZUuJD"
      },
      "source": [
        "df[['key','status.name', 'status.id']].head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWRbDhIJ42yx"
      },
      "source": [
        "df[['status.name', 'status.id']].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt7w1m2HxCni"
      },
      "source": [
        "## **R30: No previously resolved issue should reappear in a future sprint**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVerIA5xEWhQ"
      },
      "source": [
        "### **XD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yrVZWwTrNLK"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_xd = [3, 10000, 10001, 10006]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_xd)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_xd)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])\n",
        "result['to'] = result['to'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 50, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df.loc[final_df['key'] == 'XD-1510']\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['sprint', 'key']].get_group(key).to_markdown())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFlKtolBEbNA"
      },
      "source": [
        "### **APSTUD!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_XtaZ9KEi4q"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_apstud = [1, 10003, 5, 6, 4]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_apstud)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_apstud)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 10003, 5, 6, 4],[1, 5, 20, 50, 100])\n",
        "result['to'] = result['to'].replace([1, 10003, 5, 6, 4],[1, 5, 20, 50, 100])\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 50, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['sprint', 'key']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRx4zCTNEjcE"
      },
      "source": [
        "### **TISTUD!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RngIEpzvEmDI"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_tistud = [1, 3, 10003, 5, 6, 4]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_tistud)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_tistud)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "result['to'] = result['to'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 50, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['key', 'sprint']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Wf600REmzT"
      },
      "source": [
        "### **MOBILE!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7Fjcpx7EpMQ"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_mobile = [1, 3, 10005, 10010, 10012, 5, 6, 4]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_mobile)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_mobile)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 3, 10005, 10010, 10012, 5, 6, 4],[1, 5, 20, 50, 100, 200, 400, 800])\n",
        "result['to'] = result['to'].replace([1, 3, 10005, 10010, 10012, 5, 6, 4],[1, 5, 20, 50, 100, 200, 400, 800])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 400, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['key', 'sprint']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI_Z3WXZEpin"
      },
      "source": [
        "### **MDL!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG437GluErPI"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_mdl = [1, 3, 6, 4, 10012, 10013, 10010, 10004, 10005, 10006 ]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_mdl)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_mdl)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])\n",
        "result['to'] = result['to'].replace([10000, 3, 10006, 10001],[1, 5, 20, 50])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 50, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df.loc[final_df['key'] == 'XD-1510']\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['sprint', 'key']].get_group(key).to_markdown())\n",
        "\n",
        "\n",
        "#FIND ALL ISSUES WITH THE STATUS OF CLOSED OR LAST STATUS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxV5_aEbEsDe"
      },
      "source": [
        "### **DNN!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVDqu6csEuWv"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_dnn = [1, 10008, 10133, 5, 6, 4]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_dnn)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_dnn)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 10008, 10133, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "result['to'] = result['to'].replace([1, 10008, 10133, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 50, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df.loc[final_df['key'] == 'XD-1510']\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['key', 'sprint']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYpoQdEDEuxW"
      },
      "source": [
        "### **MESOS!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoYxopQzIc8N"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_mesos = [1, 3, 10006, 10020, 5]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_mesos)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_mesos)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 3, 10006, 10020, 5],[1, 5, 20, 50, 100])\n",
        "result['to'] = result['to'].replace([1, 3, 10006, 10020, 5],[1, 5, 20, 50, 100])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 50, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['key', 'sprint']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwNdm7vcIdgC"
      },
      "source": [
        "### **MULE!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDk0rH-5If3_"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_mule = [1, 3, 5, 6, 4]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_mule)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_mule)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 3, 5, 6, 4],[1, 5, 20, 50, 100])\n",
        "result['to'] = result['to'].replace([1, 3, 5, 6, 4],[1, 5, 20, 50, 100])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 50, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['key', 'sprint']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KKz6f4TIgi5"
      },
      "source": [
        "### **NEXUS!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qmkJCu_IjJj"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_nexus = [1, 10016, 10734, 10017, 6]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_nexus)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_nexus)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 10016, 10734, 10017, 6],[1, 5, 20, 50, 100])\n",
        "result['to'] = result['to'].replace([1, 10016, 10734, 10017, 6],[1, 5, 20, 50, 100])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 100, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "# final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['key', 'sprint']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufQufxqYIjc3"
      },
      "source": [
        "### **TIMOB!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpFtktszJhS2"
      },
      "source": [
        "result = pd.merge(df, df_changelog, on=\"key\", how = 'inner')\n",
        "\n",
        "result[['key', 'sprint', 'from', 'to']].head(5)\n",
        "\n",
        "result.dropna(subset = [\"sprint\"], inplace=True)\n",
        "result.dropna(subset = [\"from\"], inplace=True)\n",
        "result.dropna(subset = [\"to\"], inplace=True)\n",
        "\n",
        "result = result[~result['from'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "result = result[~result['to'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
        "\n",
        "result['from'] = pd.to_numeric(result['from'], errors='coerce')\n",
        "result['to'] = pd.to_numeric(result['to'], errors='coerce')\n",
        "\n",
        "statuses_to_keep_for_timob = [1, 3, 10003, 5, 6, 4]\n",
        "\n",
        "result = result[result['to'].isin(statuses_to_keep_for_timob)]\n",
        "result = result[result['from'].isin(statuses_to_keep_for_timob)]\n",
        "\n",
        "\n",
        "result['from'] = result['from'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "result['to'] = result['to'].replace([1, 3, 10003, 5, 6, 4],[1, 5, 20, 50, 100, 200])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "result['from'] = result['from'].apply(np.int64)\n",
        "result['to'] = result['to'].apply(np.int64)\n",
        "result[['key', 'sprint', 'from', 'to']].head(10)\n",
        "\n",
        "#result.loc[result['key'] == 'XD-3218', ['key', 'sprint', 'from', 'to']]\n",
        "#print(result.key.describe())\n",
        "#completed_issues = result.loc[result['to'] == 50, 'key'].to_list()\n",
        "# completed_issues\n",
        "\n",
        "final_df = result.loc[result['to'] == 100, ['key', 'sprint', 'from', 'to']]\n",
        "final_df.head(5)\n",
        "\n",
        "final_df = final_df[final_df.duplicated(subset=['key'], keep=False)]\n",
        "print(final_df.describe())\n",
        "\n",
        "final_df = final_df.groupby(\"key\")\n",
        "\n",
        "for key, item in final_df:\n",
        "    print(final_df[['key', 'sprint']].get_group(key).to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WBw5SbmEbGe"
      },
      "source": [
        "## **R31 - Each Scrum Sprints can be considered a short project, therefore there should be a unique identifier/name associated with each Sprint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmBO2qjWFQBc"
      },
      "source": [
        "# THIS RULE CHECKS IF ALL EXISTING SPRINTS ARE UNIQUELY IDENTIFIED, NOT IF THERE ARE ISSUES NOT BELONGING TO A SPRINT!! \n",
        "\n",
        "#print(f\"\\nTotal records of Sprints in the Open-Source Project: {df['sprint'].count()}\\n\")\n",
        "\n",
        "print(f\"Number of unique sprints (excluding the nan) in the Open-Source Project: {df.sprint.nunique()}\\n\")\n",
        "#print(df.sprint.unique())\n",
        "\n",
        "print(f\"The number of missing values in the Sprint field in the Open-Source Project is: {df.sprint.isnull().sum()}\\n\")\n",
        "print(f\"The number of non-missing values in the Sprint field in the Open-Source Project is: {df.sprint.notnull().sum()}\\n\")\n",
        "list_of_sprints = df['sprint'].unique()\n",
        "print(f'There are {len(list_of_sprints)} unique sprints in this project!\\n')\n",
        "\n",
        "if (df.sprint.nunique() == len(list_of_sprints)-1):\n",
        "  print(colored.fg(\"green\") + f\"Rule 33 Passes for project: {df.project[0]}!\")\n",
        "else:\n",
        "  print(colored.fg(\"red\") + f\"Rule 33 Fails for project: {df.project[0]} !\")\n",
        "\n",
        "#sprint_df = df[df[\"sprint\"].notna()]\n",
        "#sprint_df.sprint.drop_duplicates().sort_values(ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAnxSmK5FKaU"
      },
      "source": [
        "display(df.sprint.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDkPDJYUBkms"
      },
      "source": [
        "spike_cols = [col for col in df.columns if 'sprint' in col]\n",
        "print(list(df.columns))\n",
        "print(spike_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjv5nwT_CB4u"
      },
      "source": [
        "df['empty_sprint_IDs'] = df['sprint'].apply(lambda x: 'True' if pd.isnull(x) else 'False')\n",
        "\n",
        "df['empty_sprint_IDs'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTYQRb0Uovyg"
      },
      "source": [
        "## **R32 - There should be a type, such as bug, improvement or task, associated to each issue**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6HhBTOfo55e"
      },
      "source": [
        "# THIS RULE CHECKS IF ALL ISSUES IN THE PROJECT, ARE ASSIGNED AN ISSUE STATUS (IN PROGRESS, IN TEST, ETC.)\n",
        "# NOTE: Each project has its own types, this rule only checks if issues have types assigned to them throughout their lifecycle. \n",
        "\n",
        "\n",
        "df.rename(columns={'issuetype.name': 'types'}, inplace=True)\n",
        "\n",
        "print(f'Total number of issue types present in this Open-Source Project is: {df.types.nunique()}.')\n",
        "print('\\nThese different statuses and their number of occurence for this Open-Source Project are:')\n",
        "print(df['types'].value_counts())\n",
        "\n",
        "print('\\n\\nFinally, we are checking if there are issues having no issue types in the dataset: \\n')\n",
        "types_df = df[(df['types'].isnull()) & pd.notnull(df[\"key\"])]\n",
        "\n",
        "print(f\"There are {len(df['types'])} values present in the issuetype.name data field.\")\n",
        "print(f\"Total number of issues having no issue status is: {len(types_df[['key', 'types']])}.\\n\")\n",
        "if (len(types_df[['key', 'types']]) == 0) :\n",
        "    print(colored.fg(\"green\") + \"\\nRule 34 passed for this Open-Source Project!\\n\")\n",
        "else :\n",
        "  print(colored.fg(\"red\") + \"\\nRule 34 failed for this Open-Source Project!\\n\")\n",
        "\n",
        "types_df[['key', 'types']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA13T3jfHdoK"
      },
      "source": [
        "## **R33 - Each issue belongs to a specific Sprint, therefore there should be a sprint identifier attached to each issue**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH97zfBpH2Pr"
      },
      "source": [
        "# THIS RULE CHECKS IF ALL ISSUES IN THE PROJECT, ARE CREATED AS PART OF A RUNNING SPRINT,\n",
        "# IN THE CASE THE TEAMS WERE ORGANIZING THE WORK IN SPRINTS.\n",
        "\n",
        "print(f'Total number of unique sprints present in this Open-Source Project is: {df.sprint.nunique()}.')\n",
        "print(f'Total number of missing sprints present in this Open-Source Project is: {df.sprint.isnull().sum()}.')\n",
        "print(f'Total number of unique issues present in this Open-Source Project is: {df.key.nunique()}.')\n",
        "print(f'Total number of missing issues present in this Open-Source Project is: {df.key.isnull().sum()}.')\n",
        "\n",
        "print('\\nFinally, we are checking if there are issues having no issue statuses in the dataset: \\n')\n",
        "issue_sprint_df = df[(df['sprint'].isnull()) & pd.notnull(df[\"key\"])]\n",
        "\n",
        "print(len(issue_sprint_df[['key', 'sprint']]))\n",
        "print(f\"Total number of issues belonging to no sprints is: {len(issue_sprint_df[['key', 'sprint']])}.\\n\")\n",
        "if (len(issue_sprint_df[['key', 'sprint']]) == 0) :\n",
        "    print(colored.fg(\"green\") + \"\\nRule 38 passed for this Open-Source Project!\\n\")\n",
        "else :\n",
        "  print(colored.fg(\"red\") + \"\\nRule 38 failed for this Open-Source Project!\\n\")\n",
        "\n",
        "#issue_sprint_df[['key', 'sprint', 'resolutiondate']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtdjKqAoOq-z"
      },
      "source": [
        "## **R34 - All issues must be uniquely identifiable, therefore there should be a unique identifier associated with each issue**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDKRhfuOOwJK"
      },
      "source": [
        "# THIS RULE CHECKS IF ALL ISSUES IN THE PROJECT, WITHIN THEIR CORRESPONDING SPRINTS\n",
        "# HAVE THEIR UNIQUE ID-s, MAKING THEM IDENTIFYIABLE FROM OTHER ISSUES\n",
        "\n",
        "print(f'Total number of issues present in this Open-Source Project is: {df.key.nunique()}.')\n",
        "print(f'Total number of missing issues present in this Open-Source Project is: {df.key.isnull().sum()}.\\n')\n",
        "print(f'Total number of sprints present in this Open-Source Project is: {df.sprint.nunique()}.')\n",
        "print(f'Total number of missing sprint IDs present in this Open-Source Project is: {df.sprint.isnull().sum()}.\\n')\n",
        "\n",
        "grouped_df = df.groupby(\"sprint\")\n",
        "\n",
        "print('\\n\\n*      FIRST SPRINT       *\\n\\n')\n",
        "for key, item in grouped_df:\n",
        "    print(grouped_df[['sprint', 'key']].get_group(key).to_markdown())\n",
        "    if (pd.isnull(grouped_df['key'])):\n",
        "      print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "      #exit()\n",
        "    else:\n",
        "      print('\\n\\n*        TRUE        *\\n\\n')\n",
        "      print('\\n\\n*        NEXT SPRINT        *\\n\\n')\n",
        "    \n",
        "\n",
        "r39_df = df[(df['key'].isnull()) & pd.notnull(df[\"sprint\"])]\n",
        "\n",
        "if (len(r39_df[['key', 'sprint']]) == 0) :\n",
        "  print(colored.fg(\"green\") + \"\\nRule 36 passed for this Open-Source Project!\\n\")\n",
        "else :\n",
        "  print(colored.fg(\"red\") + \"\\nRule 36 failed for this Open-Source Project!\\n\")\n",
        "\n",
        "r39_df[['sprint', 'key']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1rjXOrUrujp"
      },
      "source": [
        "# if pd.isnull(df['key']):\n",
        "#       print('\\n\\n*        FALSEEE1        *\\n\\n')\n",
        "# else:\n",
        "#   print(\"True\")\n",
        "\n",
        "def condition(df):\n",
        "  if df['key'].notna: return \"text a\"\n",
        "  if pd.isna(df['key']): return df['key']\n",
        "\n",
        "condition(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Te_XlJtzGT"
      },
      "source": [
        "new_df = df.loc[df['description'].str.startswith('The column titles of')].copy()\n",
        "\n",
        "new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3zA8-5vjgME"
      },
      "source": [
        "## **R35 - Scrum Sprints have a starting time. There should be timestamp indicating the sprints kick-off**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbQM6-BpjhrM"
      },
      "source": [
        "# THIS RULE CHECKS IF SPRINTS WITHIN THE OPEN-SOURCE PROJECTS ARE DEFINITE IN TIME, \n",
        "# MEANING THAT EACH SPRINT MUST HAVE A STARTING TIME AS WELL AS AN ENDING TIME.\n",
        "\n",
        "# EXPLANATION: Since not all projects have defined sprints start and end time,\n",
        "# for other projects I am grouping the issues as per the sprint they were implemented in.\n",
        "# After that, I am only displaying the first issue and last issue of the specific sprint.\n",
        "# This way, we can see the start time of the first issue, i.e. the start time of the sprint,\n",
        "# as well as the end time of the last issue from that sprint, i.e. the end time of the sprint itself.\n",
        "\n",
        "print(f\"Number of unique sprints (excluding the nan) in the Open-Source Project: {df.sprint.nunique()}\\n\")\n",
        "print(df.sprint.unique())\n",
        "print('\\n\\n')\n",
        "#df[['sprint', 'key', 'created', 'resolutiondate']].groupby(['sprint'])\n",
        "sprint_start_time_df = df[['sprint', 'key', 'created', 'resolutiondate' ]].groupby(['sprint'])\n",
        "display(sprint_start_time_df.tail(1).sort_values(['sprint', 'created'], ascending=[True, True]))\n",
        "# (pd.concat([g.tail(1), g.head(1)])\n",
        "#    .drop_duplicates()\n",
        "#    .sort_values(['sprint', 'created'], ascending=[True, True])\n",
        "#    .reset_index(drop=True))\n",
        "\n",
        "if pd.isnull(sprint_start_time_df.resolutiondate) == True:\n",
        "    print(colored.fg(\"red\") + \"\\nRule 40 failed for this Open-Source Project!\\n\")\n",
        "else:\n",
        "    print(colored.fg(\"green\") + \"\\nRule 40 passed for this Open-Source Project!\\n\")\n",
        "\n",
        "\n",
        "if df['sprint'].str.contains('startDate=null').any():\n",
        "  print(\"Yep\")\n",
        "else:\n",
        "  print(\"No\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiqXd5lKvfXL"
      },
      "source": [
        "start_dates_count = df['sprint'].str.contains('startDate=').sum()\n",
        "if start_dates_count > 0:\n",
        "    print (\"There are {m} sprints\".format(m=start_dates_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBZkb8Q_voqs"
      },
      "source": [
        "#df['sprint'].str.contains('startDate=')\n",
        "\n",
        "if df['key'].isnull().any():\n",
        "    print(\"Yep\")\n",
        "else:\n",
        "  print(\"No\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7L14Sd7vG-T"
      },
      "source": [
        "if df['sprint'].str.contains('startDate=').any():\n",
        "  print(\"True\")\n",
        "else :\n",
        "  print(\"False\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ELzFznopAS2"
      },
      "source": [
        "df[['sprint', 'key', 'created', 'resolutiondate']].groupby(['sprint']).apply(display)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI25XfAtfS_x"
      },
      "source": [
        "## **R36 - Scrum Sprints have a completion time. There should be timestamp indicating the sprints completion/resolution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb2Ym2HAfmAQ"
      },
      "source": [
        "# THIS RULE CHECKS IF SPRINTS WITHIN THE OPEN-SOURCE PROJECTS ARE DEFINITE IN TIME, \n",
        "# MEANING THAT EACH SPRINT MUST HAVE A STARTING TIME AS WELL AS AN ENDING TIME.\n",
        "\n",
        "# EXPLANATION: Since not all projects have defined sprints start and end time,\n",
        "# for other projects I am grouping the issues as per the sprint they were implemented in.\n",
        "# After that, I am only displaying the first issue and last issue of the specific sprint.\n",
        "# This way, we can see the start time of the first issue, i.e. the start time of the sprint,\n",
        "# as well as the end time of the last issue from that sprint, i.e. the end time of the sprint itself.\n",
        "\n",
        "print(f\"Number of unique sprints (excluding the nan) in the Open-Source Project: {df.sprint.nunique()}\\n\")\n",
        "print(df.sprint.unique())\n",
        "print('\\n\\n')\n",
        "#df[['sprint', 'key', 'created', 'resolutiondate']].groupby(['sprint'])\n",
        "sprint_end_time_df = df[['sprint', 'key', 'resolutiondate']].groupby(['sprint'])\n",
        "display(sprint_end_time_df.head(1).sort_values(['sprint', 'resolutiondate'], ascending=[True, True]))\n",
        "# (pd.concat([g.tail(1), g.head(1)])\n",
        "#    .drop_duplicates()\n",
        "#    .sort_values(['sprint', 'created'], ascending=[True, True])\n",
        "#    .reset_index(drop=True))\n",
        "if pd.isnull(sprint_end_time_df.resolutiondate):\n",
        "  print(colored.fg(\"red\") + \"\\nRule 38 failed for this Open-Source Project!\\n\")\n",
        "else:\n",
        "  print(colored.fg(\"green\") + \"\\nRule 38 passed for this Open-Source Project!\\n\")\n",
        "\n",
        "\n",
        "if df['sprint'].str.contains('endDate=null').any():\n",
        "  print(\"Yep\")\n",
        "else:\n",
        "  print(\"No\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz_DghfbPs1A"
      },
      "source": [
        "## **R37 - There should be a minimum of one issue, representing a Sprint Backlog Item, per each Sprint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58PMhxvsPxDt"
      },
      "source": [
        "# THIS RULE CHECKS IF ANY OF THE SPRINTS WITHIN THE OPEN-SOURCE PROJECTS\n",
        "# CONTAINS NO ISSUES, i.e. NO PRODUCT BACKLOG ITEMS/SPRINT BACKLOG ITEMS \n",
        "\n",
        "\n",
        "print(f\"\\n The sprint with most completed issues is: {df.groupby('sprint').count().key.idxmax()}\\n\")\n",
        "\n",
        "\n",
        "counts = df[['key', 'sprint']].groupby(['sprint']).describe()\n",
        "display(counts)\n",
        "print('\\n\\n')\n",
        "\n",
        "pbis_per_sprint = df.groupby(['sprint'])['key'].apply(lambda grp: list(grp.value_counts().index)).to_dict()\n",
        "print(pbis_per_sprint)\n",
        "\n",
        "\n",
        "\n",
        "# the logic of this sprint is that the sprints' length is not 0, meaning that each sprint has some issues or PBIs within. \n",
        "value = input(\"Check a number of PBIs that sprints might have: \")\n",
        "\n",
        "total_pbis_per_sprint = [len(v) for v in pbis_per_sprint.values()]\n",
        "\n",
        "\n",
        "# check if value of 0 exist in dict using \"in\" & values()\n",
        "if pd.to_numeric(value) == 0:\n",
        "  if pd.to_numeric(value) in total_pbis_per_sprint :\n",
        "    print(f\"\\nYes, this project contains sprints which have {value} PBIs!\")\n",
        "    print(colored.fg(\"red\") + \"\\nRule 42 failed for this Open-Source Project!\\n\")\n",
        "  else: \n",
        "    print(f\"\\nNo, this project does not contain sprints with {value} PBIs!\")\n",
        "    print(colored.fg(\"green\") + \"\\nRule 42 passed for this Open-Source Project!\\n\")\n",
        "elif pd.to_numeric(value) != 0 and pd.to_numeric(value) in total_pbis_per_sprint:\n",
        "  print(f\"\\nYes, this project contains sprints which have {value} PBIs!\")  \n",
        "  #print(colored.fg(\"green\") + \"\\nRule 42 passed for this Open-Source Project!\\n\")\n",
        "else:\n",
        "  print(f\"\\nNo, this project does not contain sprints with '{value}' PBIs!\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCOmTuFIKbqA"
      },
      "source": [
        "## **R38 - There should be timestamp indicating the issue development kick-off**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP-CFi-RLSPk"
      },
      "source": [
        "import colored\n",
        "\n",
        "print(f\"\\nTotal number of issues in the Open-Source Project are: {df['key'].count()}.\")\n",
        "\n",
        "print(f\"Total number of unique issues (excluding nan) in the Open-Source Project are: {df.key.nunique()}. \\n\")\n",
        "print('\\nThese issues are as printed below:')\n",
        "print(df.key.unique())\n",
        "\n",
        "\n",
        "# Selecting all duplicate rows based on column: key\n",
        "duplicateRowsDF = df[df.duplicated(['key'])]\n",
        "print(f\"\\nThere are: {len(duplicateRowsDF)} issue duplicates!\")\n",
        "\n",
        "# Here I am removing all issue duplicates, while only keeping the first instance!\n",
        "print('In case of duplicate issues, the duplicates will be removed! However, this step was already performed in the data cleaning part.')\n",
        "df = df.drop_duplicates(subset='key', keep='first')\n",
        "\n",
        "print(f\"\\nTotal number of issues (key column), after cleaning is: {df['key'].count()}\\n\")\n",
        "print(f\"{df['key'].value_counts().head(10)}\\n\\n\")\n",
        "print(f\"Total number of missing values in the *key* column in the Open-Source Project: {df.key.isnull().sum()}.\\n\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "\n",
        "print('\\n\\nFinally, we are checking if there are issues having no start date left in the dataset: \\n')\n",
        "startdate_df = df[(df['created'].isnull()) & pd.notnull(df[\"key\"])]\n",
        "\n",
        "print(f\"Total number of issues having no created date is: {len(startdate_df[['key', 'created']])}.\\n\")\n",
        "if (len(startdate_df[['key', 'created']]) == 0) :\n",
        "  print(colored.fg(\"green\") + \"\\nRule 40 passed for this Open-Source Project!\\n\")\n",
        "else :\n",
        "  print(colored.fg(\"red\") + \"\\nRule 40 failed for this Open-Source Project!\\n\")\n",
        "\n",
        "startdate_df[['key', 'created']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WZbO8oULT8V"
      },
      "source": [
        "## **R39 - There should be timestamp indicating the issue development completion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW1aecPwLXUS"
      },
      "source": [
        "print(f\"\\nTotal number of issues in the Open-Source Project are: {df['key'].count()}.\")\n",
        "\n",
        "print(f\"Total number of unique issues (excluding nan) in the Open-Source Project are: {df.key.nunique()}. \\n\")\n",
        "print('\\nThese issues are as printed below:')\n",
        "print(df.key.unique())\n",
        "\n",
        "\n",
        "# Selecting all duplicate rows based on column: key\n",
        "duplicateRowsDF = df[df.duplicated(['key'])]\n",
        "print(f\"\\nThere are: {len(duplicateRowsDF)} issue duplicates!\")\n",
        "\n",
        "\n",
        "# Here I am removing all issue duplicates, while only keeping the first instance!\n",
        "print('In case of duplicate issues, the duplicates will be removed! However, this step was already performed in the data cleaning part.')\n",
        "df = df.drop_duplicates(subset='key', keep='first')\n",
        "\n",
        "print(f\"\\nTotal number of issues (key column), after cleaning is: {df['key'].count()}\\n\")\n",
        "print(f\"{df['key'].value_counts().head(10)}\\n\\n\")\n",
        "print(f\"Total number of missing values in the *key* column in the Open-Source Project: {df.key.isnull().sum()}.\\n\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "\n",
        "print('\\n\\nFinally, we are checking if there are issues having no end date left in the dataset: \\n')\n",
        "enddate_df = df[(df['resolutiondate'].isnull()) & pd.notnull(df[\"key\"])]\n",
        "\n",
        "print(f\"Total number of issues having no end date is: {len(enddate_df[['key', 'resolutiondate']])}.\\n\")\n",
        "if (len(enddate_df[['key', 'created']]) == 0) :\n",
        "    print(colored.fg(\"green\") + \"\\nRule 41 passed for this Open-Source Project!\\n\")\n",
        "else :\n",
        "  print(colored.fg(\"red\") + \"\\nRule 41 failed for this Open-Source Project!\\n\")\n",
        "enddate_df[['key', 'resolutiondate', 'sprint']]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}